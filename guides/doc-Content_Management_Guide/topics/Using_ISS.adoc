[[Using_ISS]]
== Synchronizing Content Between {ProjectServer}s

{ProjectName} uses {Project}'s Inter-Server Synchronization (ISS) to synchronize content between two {ProjectServer}s including those that are airgapped.


=== Scenarios
* If you want to copy some but not all content from your {ProjectServer} to other {ProjectServer}s.
For example, you have Content Views that your IT department consumes content from {ProjectServer}, and you want to copy content from those Content Views to other {ProjectServer}s.

* If you want to copy all library content from your {ProjectServer} to another {ProjectServer}s.
For example, you have Products and repositories that your IT department consumes content from {ProjectServer} in the Library, and you want to copy all Products and repositories in that organization to another {ProjectServer}s.

* If you have both connected and disconnected {ProjectServer}s, and want to copy content from the connected servers to the disconnected servers.
For example, you require complete isolation of your management infrastructure for security or other purposes.

These scenarios require at least two {ProjectServer}s: one {ProjectServer} that is connected to the outside world and contains content to export, and another {ProjectServer} that is disconnected that you want to import content to.

[[img-disconnected]]

ifndef::satellite[]
image::Disconnected.png[title="The {Project} ISS use cases", alt="The {Project} ISS use cases"]
endif::[]

You cannot use ISS to synchronize content from {ProjectServer} to {SmartProxyServer}.
{SmartProxyServer} supports synchronization natively.
For more information, see {PlanningDocURL}chap-Documentation-Architecture_Guide-Capsule_Server_Overview[{SmartProxyServer} Overview] in _Planning for {ProjectNameX}_.

=== Configuration Definitions
There are different ways of using ISS to synchronize content between two {ProjectServer}s.

.Connected
In a connected scenario, two {ProjectServer}s are able to communicate with each other.

ifndef::satellite[]
image::Connected.png[title="The {Project} ISS Connected use case", alt="The {Project} ISS Connected use case"]
endif::[]

.Disconnected
In a disconnected scenario, there is the following setup:

* Two {ProjectServer}s are connected to each other.
* One {ProjectServer} is connected to the Internet while the other {ProjectServer} is not connected to the Internet.
** This is referred to as the disconnected {ProjectServer}.
* The disconnected {ProjectServer} is completely isolated from all external networks but can communicate with a connected {ProjectServer}.

ifndef::satellite[]
image::Non-Airgapped-Disconnected.png[title="The {Project} ISS Non Airgapped Disconnected use case", alt="The {Project} ISS Airgapped Disconnected use case"]
endif::[]


.Air-gapped Disconnected
In this setup, both {ProjectServer}s are isolated from each other.
The only way for air-gapped {ProjectServer}s to receive content updates is through the import/export workflow.

ifndef::satellite[]
image::Airgapped-Disconnected.png[title="The {Project} ISS Airgapped Disconnected use case", alt="The {Project} ISS Airgapped Disconnected use case"]
endif::[]

=== Exporting from a Connected {ProjectServer}

==== Connected {ProjectServer} as a Content Store

In this scenario, you have one connected {ProjectServer} that is receiving content from an external source like the CDN.
The rest of your infrastructure is completely isolated, including another disconnected {ProjectServer}.
The connected {ProjectServer} is mainly used as a content store for updates.
The disconnected {ProjectServer} serves as the main {ProjectServer} for managing content for all infrastructure behind the isolated network.

.On the connected {ProjectServer}

. Ensure that repositories are using the immediate download policy, either by:
.. For existing repos using *On Demand*, change their download policy on the repository details page to *Immediate*.
.. For new repositories, ensure that the *Default Red Hat Repository download policy* setting is set to *Immediate* before enabling Red Hat repositories, and that the *Default download policy* is set to *Immediate* for custom repositories
.. see xref:Importing_Content-Configuring_Download_Policies[] for more information.
. Enable the content that you want to use (refer to xref:Importing_Content-Selecting_Red_Hat_Repositories_to_Synchronize[].)
. Synchronize the enabled content.
. For the first export, perform a `complete Library` export so that all the synchronized content are exported.
This  generates content archives that you can later import into one or more disconnected {ProjectServer}s.
For more information on performing a complete Library export, see xref:Using_ISS-Exporting-Library[].
. Export all future updates in the connected {ProjectServer}s incrementally.
This generates leaner content archives that contain changes only from the recent set of updates.
For example, if you enable and synchronize a new repository, the next exported content archive contains content only from the newly enabled repository.
For more information on performing an incremental Library export, see xref:Using_ISS-Exporting-Library-Incremental[].


.On the disconnected {ProjectServer}

. Copy the exported content archive that you want from the connected {ProjectServer}.
. Import content to an organization using the procedure outlined in xref:Using_ISS-Importing-Library[].
You can then manage content using Content Views or Lifecycle Environments as you require on the disconnected {ProjectServer}.

==== Connected {ProjectServer} for managing Content View Versions

In this scenario, your connected {ProjectServer} is receiving content from an external source like the CDN. The rest of your infrastructure is completely isolated, including a disconnected {ProjectServer}.
However, the connected {ProjectServer} is not only used as a content store, but also is used to manage content.
Updates coming from the CDN are curated into Content Views and Lifecycle Environments.
Once the content has been promoted to a designated Lifecycle Environment, the content can be exported and imported into the disconnected {ProjectServer}.

.On the connected {ProjectServer}
. Ensure that repositories are using the immediate download policy, either by:
.. For existing repos using *On Demand* change their download policy on the repository details page to *Immediate*.
.. For new repositories, ensure that the *Default Red Hat Repository download policy* setting is set to *Immediate* before enabling RH repos, and *Default download policy* is set to *Immediate* for custom repositories
see xref:Importing_Content-Configuring_Download_Policies[] for more information.
. Enable any content that you want to use (refer to xref:Importing_Content-Selecting_Red_Hat_Repositories_to_Synchronize[].)
. Synchronize the enabled content.
. When you have new content republish the Content Views that include this content (see xref:Managing_Content_Views[].) This should create a new Content View Version with the appropriate content to export.
. For the first export, perform a `complete version` export on the Content View Version that you want to export.
For more information see, xref:Using_ISS-Exporting-a-Content-View-Version[].
This generates content archives that you can import into one or more disconnected {ProjectServer}s.
. Export all future updates in the connected {ProjectServer}s incrementally.
This generates leaner content archives that contain changes only from the recent set of updates.
For example, if your Content View has a new repository, this exported content archive  contains only the latest changes.
For more information on performing an incremental export on Content View Versions, see xref:Using_ISS-Exporting-a-Content-View-Version-Incremental[].

.On the disconnected {ProjectServer}

. Copy the exported content archive from the connected {ProjectServer}.
. Import the content to the organization that you want.
For more information, see xref:Using_ISS-Importing-Content-View-Version[].
This will create a content view version from the exported content archives and them import  content appropriately.

=== Keeping track of your exports

If you are exporting content to several disconnected {ProjectServer}s then using a `--destination-server` option  provides a way to organize or maintain a record of what versions got exported to a given destination.
For more information, see xref:Using_ISS-Destination-Server[].

This option is available for all content-export operations. You can use the `destination-server` to

* Query what was previously exported to a given destination.
* Generate incremental exports automatically to the given destination server.

[[Using_ISS-Exporting-a-Content-View-Version]]
=== Exporting a Content View Version

You can export a version of a Content View to an archive file from {ProjectServer} and use this archive file to create the same Content View version on another {ProjectServer} or on another {ProjectServer} organization.
{Project} does not export composite Content Views.
The exported archive file contains the following data:

* A JSON file containing Content View version metadata
* An archive file containing all the repositories included into the Content View version

{ProjectServer} exports only RPM and kickstart files added to a version of a Content View.
{Project} does not export the following content:

* Docker content
* Content View definitions and metadata, such as package filters.

.Prerequisites

To export a Content View, ensure that {ProjectServer} where you want to export meets the following conditions:

* Ensure that the export directory has free storage space to accommodate the export.
* Ensure that the `/var/lib/pulp/exports` directory has free storage space equivalent to the size of the repositories being exported for temporary files created during the export process.
* Ensure that you set download policy to *Immediate* for all repositories within the Content View you export.
For more information, see xref:Importing_Content-Configuring_Download_Policies[].
* Ensure that you synchronize Products that you export to the required date.
* Ensure that the user exporting the content has the `Content Exporter` role.

.To Export a Content View Version:

. List versions of the Content View that are available for export:
+
[subs="+quotes"]
----

# hammer content-view version list \
--organization=export-org \
 --content-view=view

---|----------|---------|-------------|-----------------------
ID | NAME     | VERSION | DESCRIPTION | LIFECYCLE ENVIRONMENTS
---|----------|---------|-------------|-----------------------
5  | view 3.0 | 3.0     |             | Library
4  | view 2.0 | 2.0     |             |
3  | view 1.0 | 1.0     |             |
---|----------|---------|-------------|----------------------

----

.Export a Content View version
Get the version number of desired version. The following example targets version `1.0` for export.

[options="nowrap" subs="+quotes"]
----
# hammer content-export complete version \
--content-view=view --version=1.0 \
--organization=export-21527
----

. Verify that the archive containing the exported version of a Content View is located in the export directory:
+
[options="nowrap" subs="+quotes"]
----
# ls -lh /var/lib/pulp/exports/export-21527/view/1.0/2021-02-25T18-59-26-00-00/

----

. You require all three files, for example, the `tar.gz` archive file, the `toc.json` and `metadata.json` to import the content successfully.

.Export with chunking

In many cases, the exported archive content can be several gigabytes in size.
You might want to split it into smaller sizes or chunks.
You can use the `--chunk-size-gb` option with the `hammer content-export` command to handle this.
The following example uses the `--chunk-size-gb=2` to split the archives into `2 GB` chunks.


[options="nowrap" subs="+quotes"]
----
# hammer content-export complete version --content-view=view --version=1.0 --organization=export-21527 --chunk-size-gb=2

# ls -lh  /var/lib/pulp/exports/export-21527/view/1.0/2021-02-25T21-15-22-00-00/
----

[[Using_ISS-Destination-Server]]
=== Keeping track of your exports

When importing content to several {ProjectServer}s, the --destination-server option is especially useful for keeping track of which content was exported and to where.

You can use this flag to let the exporting {ProjectServer} keep track of content in specific servers.
The `--destination-server` option functions to indicate the destination server that your content is imported to.
The following example uses `--destination-server=mirror1` to export content to `mirror1`.
The archive is created on the exporting {ProjectServer}.
However, a record of each export is also maintained.
This can be very useful when incrementally exporting.

[options="nowrap" subs="+quotes"]
----
# hammer content-export complete version \
--content-view=view --version=1.0 \
--organization=export-21527 \
--destination-server=mirror1
----

[[Using_ISS-Exporting-a-Content-View-Version-Incremental]]
.Incremental Export

Exporting complete versions can be a very expensive operation on storage space and resources. Content View versions that have multiple {RHEL} trees can occupy several gigabytes of the space on {ProjectServer}.

You can use the *Incremental Export* functionality to help reduce demands on your infrastructure.
*Incremental Export* exports only content that changes from the previously exported version.
Generally, incremental changes are smaller than full exports.
ln the following example, since version `1.0` has already been exported and the command targets version 2.0 for export.
To use incremental export, complete the following steps.

----
# hammer content-export incremental version \
 --content-view=view \
 --version=2.0 \
 --organization=export-21527

# ls -lh /var/lib/pulp/exports/export-21527/view/2.0/2021-02-25T21-45-34-00-00/
----

=== Examining the exports

You can query on the exports that you previously have created via the `hammer content-export list` command.

----
hammer content-export list --organization=export-21527

---|--------------------|-----------------------------------------------------------------------|-------------|----------------------|-------------------------|-------------------------|------------------------
ID | DESTINATION SERVER | PATH                                                                  | TYPE        | CONTENT VIEW VERSION | CONTENT VIEW VERSION ID | CREATED AT              | UPDATED AT
---|--------------------|-----------------------------------------------------------------------|-------------|----------------------|-------------------------|-------------------------|------------------------
1  |                    | /var/lib/pulp/exports/export-21527/view/1.0/2021-02-25T18-59-26-00-00 | complete    | view 1.0             | 3                       | 2021-02-25 18:59:30 UTC | 2021-02-25 18:59:30 UTC
2  |                    | /var/lib/pulp/exports/export-21527/view/1.0/2021-02-25T21-15-22-00-00 | complete    | view 1.0             | 3                       | 2021-02-25 21:15:26 UTC | 2021-02-25 21:15:26 UTC
3  |                    | /var/lib/pulp/exports/export-21527/view/2.0/2021-02-25T21-45-34-00-00 | incremental | view 2.0             | 4                       | 2021-02-25 21:45:37 UTC | 2021-02-25 21:45:37 UTC
---|--------------------|-----------------------------------------------------------------------|-------------|----------------------|-------------------------|-------------------------|------------------------
----

[[Using_ISS-Importing-Content-View-Version]]
=== Importing a Content View Version

You can use the archive that the `hammer content-export` command outputs to create a version of a Content View with the same content as the exported Content View version.
For more information about exporting a Content View version, see xref:Using_ISS-Exporting-a-Content-View-Version[].

When you import a Content View version, it has the same major and minor version numbers and contains the same repositories with the same packages and errata.
The Custom Repositories, Products and Content Views are automatically created if they do not exist in the importing organization.

.Prerequisites

To import a Content View, ensure that {ProjectServer} where you want to import meets the following conditions:

. The exported archive must be in a directory under `/var/lib/pulp/imports`.
. The directory must have `pulp:pulp` permissions so that Pulp can read and write the `.json` files in that directory.
. If there are any Red Hat repositories in the export archive, the importing organization's manifest must contain subscriptions for the products contained within the export.
. The user importing the content view version must have the 'Content Importer' Role.


.Procedure

. Copy the archived file with the exported Content View version to the `/var/lib/pulp/imports` directory on {ProjectServer} where you want to import.
. Set the user:group permission of the archive files to `pulp:pulp`.
+
[subs="+quotes"]
----
# chown -R pulp:pulp /var/lib/pulp/imports/2021-02-25T21-15-22-00-00/
----
+
. Verify that the permission change occurs:
+
[subs="+quotes"]
----
# ls -lh  /var/lib/pulp/imports/2021-02-25T21-15-22-00-00/

----

. To import the Content View version to {ProjectServer}, enter the following command:
+
[subs="+quotes"]
----
# hammer content-import version --organization=import-20639 \
                                --path=/var/lib/pulp/imports/2021-02-25T21-15-22-00-00/
----
+
Note that you must enter the full path `/var/lib/pulp/imports/<path>`. Relative paths do not work.
+
. To verify that you import the Content View version successfully, list Content Views for your organization:
+
[subs="+quotes"]
----
# hammer content-view version list --content-view=view \
                                   --organization=import-20639
---|----------|---------|-------------|-----------------------
ID | NAME     | VERSION | DESCRIPTION | LIFECYCLE ENVIRONMENTS
---|----------|---------|-------------|-----------------------
7  | view 1.0 | 1.0     |             | Library
---|----------|---------|-------------|-----------------------
----




[[Using_ISS-Exporting-Library]]
=== Exporting the Library Environment

You can export contents of all Yum repositories in the Library environment of an organization to an archive file from {ProjectServer} and use this archive file to create the same repositories in another {ProjectServer} or in another {ProjectServer} organization.
The exported archive file contains the following data:

* A JSON file containing Content View version metadata
* An archive file containing all the repositories from the Library environment of the organization.

{ProjectServer} exports only RPM and kickstart files included in a Content View  version.
{Project} does not export the following content:

* Docker content

.Prerequisites

To export the contents of the Library lifecycle environment of the organization, ensure that {ProjectServer} where you want to export meets the following conditions:

* Ensure that the export directory has free storage space to accommodate the export.
* Ensure that the `/var/lib/pulp/exports` directory has free storage space equivalent to the size of the repositories being exported for temporary files created during the export process.
* Ensure that you set download policy to *Immediate* for all repositories within the Library lifecycle environment you export.
For more information, see xref:Importing_Content-Configuring_Download_Policies[].
* Ensure that you synchronize Products that you export to the required date.

.To Export the Library Content of an Organization:

Use the organization name or ID to export.

[options="nowrap" subs="+quotes"]
----
# hammer content-export complete library --organization=export-21527
----

. Verify that the archive containing the exported version of a Content View is located in the export directory:
+
[options="nowrap" subs="+quotes"]
----
# ls -lh /var/lib/pulp/exports/export-21527/Export-Library/1.0/2021-03-02T03-35-24-00-00
total 68M
-rw-r--r--. 1 pulp pulp 68M Mar  2 03:35 export-1e25417c-6d09-49d4-b9a5-23df4db3d52a-20210302_0335.tar.gz
-rw-r--r--. 1 pulp pulp 333 Mar  2 03:35 export-1e25417c-6d09-49d4-b9a5-23df4db3d52a-20210302_0335-toc.json
-rw-r--r--. 1 root root 443 Mar  2 03:35 metadata.json
----

. You require all three files, for example, the `tar.gz`, the `toc.json` and the `metadata.json` file to be able to import.
. A new Content View  **Export-Library** is created in the organization. This content view contains all the repositories belonging to this organization. A new version of this Content View is published and exported automatically.

.Export with chunking

In many cases the exported archive content may be several gigabytes in size.
If you want to split it into smaller sizes or chunks.
You can use the `--chunk-size-gb` flag directly in the export command to handle this.
In the following example, you can see how to specify `--chunk-size-gb=2` to split the archives in `2 GB` chunks.

[options="nowrap" subs="+quotes"]
----
# hammer content-export complete library --organization=export-21527 --chunk-size-gb=2
[.....................................................................................................................................................................................................................................] [100%]
Generated /var/lib/pulp/exports/export-21527/Export-Library/2.0/2021-03-02T04-01-25-00-00/metadata.json

# ls -lh /var/lib/pulp/exports/export-21527/Export-Library/2.0/2021-03-02T04-01-25-00-00/
----

[[Using_ISS-Exporting-Library-Incremental]]
.Incremental Export

Exporting Library content can be a very expensive operation in terms of space and resources. Organization that have multiple RHEL trees may occupy several gigabytes of the space on {ProjectServer}.

{ProjectServer} offers *Incremental Export* to help with this scenario.
*Incremental Export* exports only things that changed from the previous export.
These would be typically smaller than the full exports.
In the example below we will incrementally export what changed from the previous export of all the repositories in the Library lifecycle environment.

[options="nowrap" subs="+quotes"]
----
# hammer content-export incremental library --organization=export-21527
[............................................................................................................................................................................................................] [100%]
Generated /var/lib/pulp/exports/export-21527/Export-Library/3.0/2021-03-02T04-22-14-00-00/metadata.json
# ls -lh /var/lib/pulp/exports/export-21527/Export-Library/3.0/2021-03-02T04-22-14-00-00/
total 172K
-rw-r--r--. 1 pulp pulp 161K Mar  2 04:22 export-436882d8-de5a-48e9-a30a-17169318f908-20210302_0422.tar.gz
-rw-r--r--. 1 pulp pulp  333 Mar  2 04:22 export-436882d8-de5a-48e9-a30a-17169318f908-20210302_0422-toc.json
-rw-r--r--. 1 root root  492 Mar  2 04:22 metadata.json
----
. Since nothing changed between the previous export and now in the Organization's library environment the change files are really small.

[[Using_ISS-Importing-Library]]
=== Importing into the Library Environment

You can use the archive that the `hammer content-export` command outputs to import into the Library lifecycle environment of another organization
For more information about exporting contents from the Library environment, see xref:Using_ISS-Exporting-Library[].

.Prerequisites

To import in to an Organization's library lifecycle environment  ensure that {ProjectServer} where you want to import meets the following conditions:

. The exported archive must be in a directory under `/var/lib/pulp/imports`.
. The directory must have `pulp:pulp` permissions so that Pulp can read and write the `.json` files in that directory.
. If there are any Red Hat repositories in the export archive, the importing organization's manifest must contain subscriptions for the products contained
within the export.
. The user importing the content must have the 'Content Importer' Role.

.Procedure

. Copy the archived file with the exported Content View version to the `/var/lib/pulp/imports` directory on {ProjectServer} where you want to import.
. Set the permission of the archive files to `pulp:pulp`.
+
[subs="+quotes"]
----
# chown -R pulp:pulp /var/lib/pulp/imports/2021-03-02T03-35-24-00-00
# ls -lh /var/lib/pulp/imports/2021-03-02T03-35-24-00-00
total 68M
-rw-r--r--. 1 pulp pulp 68M Mar  2 04:29 export-1e25417c-6d09-49d4-b9a5-23df4db3d52a-20210302_0335.tar.gz
-rw-r--r--. 1 pulp pulp 333 Mar  2 04:29 export-1e25417c-6d09-49d4-b9a5-23df4db3d52a-20210302_0335-toc.json
-rw-r--r--. 1 pulp pulp 443 Mar  2 04:29 metadata.json

----
+
. On {ProjectServer} where you want to import, create/enable repositories the same name and label as the exported content.
. In the {Project} web UI, navigate to *Content* > *Products*, click the *Yum content* tab and add the same `Yum` content that the exported Content View version includes.
. Identify the Organization that you wish to import into.
. To import the Library content to {ProjectServer}, enter the following command:
+
[subs="+quotes"]
----
# hammer content-import library --organization=import-32158 \
                                --path=/var/lib/pulp/imports/2021-03-02T03-35-24-00-00
[............................................................................................................................................................................................................] [100%]
----
+
Note you must enter the full path `/var/lib/pulp/imports/<path>`. Relative paths do not work.
+
. To verify that you imported the Library content, check the contents of the Product and Repositories.
A new Content View called `Import-Library` is created in the target organization.
This Content View is used to facilitate the library content import.

include::../common/modules/proc_exporting-a-repository.adoc[leveloffset=+2]

include::../common/modules/proc_exporting-a-repository-incrementally.adoc[leveloffset=+2]

include::../common/modules/proc_importing-a-repository.adoc[leveloffset=+2]

include::../common/modules/ref_iss-import-export-cheat-sheet.adoc[leveloffset=+2]
